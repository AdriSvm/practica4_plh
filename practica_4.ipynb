{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√†ctica 4\n",
    "### Part I : Entrenament de models Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_sm-3.5.0/ca_core_news_sm-3.5.0-py3-none-any.whl (19.6 MB)\n",
      "     ---------------------------------------- 19.6/19.6 MB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from ca-core-news-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.30.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (65.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: ca-core-news-sm\n",
      "Successfully installed ca-core-news-sm-3.5.0\n",
      "\u001B[38;5;2m[+] Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('ca_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_sm-3.5.0/ca_core_news_sm-3.5.0-py3-none-any.whl (19.6 MB)\n",
      "     ---------------------------------------- 19.6/19.6 MB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from ca-core-news-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.30.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (65.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adria\\ia\\4t quadri\\plh\\env\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->ca-core-news-sm==3.5.0) (2.1.2)\n",
      "\u001B[38;5;2m[+] Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('ca_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!py -m spacy download ca_core_news_sm\n",
    "import spacy\n",
    "nlp = spacy.load('ca_core_news_sm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset catalan_general_crawling (C:/Users/adria/.cache/huggingface/datasets/projecte-aina___catalan_general_crawling/default/1.0.0/fb8a4dbf3849d7aad584ad030c058c67c6a935ee7b8d6e37411514da9376a2fb)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a44e5f4d4974f5bbcac32df4f2505b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "dataset = load_dataset(\"projecte-aina/catalan_general_crawling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with open('data/ca_gen_crwlng.txt','w',encoding='UTF-8') as f:\n",
    "    for i in dataset['train']['text']:\n",
    "        f.write(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from gensim.utils import simple_preprocess\n",
    "STOPWORDS_CA = {\"a\", \"al\", \"el\", \"la\", \"els\", \"les\", \"de\", \"un\", \"una\", \"algun\", \"alguna\", }\n",
    "\n",
    "\n",
    "def preprocess(sentence: str) -> List[str]:\n",
    "    preprocessed = simple_preprocess(sentence)\n",
    "    preprocessed = [token for token in preprocessed if token not in STOPWORDS_CA]\n",
    "    return preprocessed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def obtain_words(filepath:str) -> list[list[str]]:\n",
    "    if filepath[-4:] != '.txt':\n",
    "        raise Exception('Incorrect file path/name')\n",
    "\n",
    "    txt_crps = []\n",
    "    with open(filepath,'r',encoding='UTF-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            txt_crps.append(preprocess(l))\n",
    "\n",
    "    return txt_crps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "txt_crps100 = obtain_words('data/ca_gen_crwlng100M.txt')\n",
    "txt_crps500 = obtain_words('data/ca_gen_crwlng500M.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m word2vec\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mword2vec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mWord2Vec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtxt_crps\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvector_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\IA\\4t Quadri\\PLH\\env\\Lib\\site-packages\\gensim\\models\\word2vec.py:430\u001B[0m, in \u001B[0;36mWord2Vec.__init__\u001B[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001B[0m\n\u001B[0;32m    428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_corpus_sanity(corpus_iterable\u001B[38;5;241m=\u001B[39mcorpus_iterable, corpus_file\u001B[38;5;241m=\u001B[39mcorpus_file, passes\u001B[38;5;241m=\u001B[39m(epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    429\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_vocab(corpus_iterable\u001B[38;5;241m=\u001B[39mcorpus_iterable, corpus_file\u001B[38;5;241m=\u001B[39mcorpus_file, trim_rule\u001B[38;5;241m=\u001B[39mtrim_rule)\n\u001B[1;32m--> 430\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus_iterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorpus_count\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorpus_total_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_alpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43mend_alpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin_alpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompute_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    435\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trim_rule \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\IA\\4t Quadri\\PLH\\env\\Lib\\site-packages\\gensim\\models\\word2vec.py:1073\u001B[0m, in \u001B[0;36mWord2Vec.train\u001B[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m   1070\u001B[0m     callback\u001B[38;5;241m.\u001B[39mon_epoch_begin(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1072\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m corpus_iterable \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1073\u001B[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1074\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcur_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcur_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_examples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1075\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqueue_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueue_factor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport_delay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreport_delay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1076\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1078\u001B[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_epoch_corpusfile(\n\u001B[0;32m   1079\u001B[0m         corpus_file, cur_epoch\u001B[38;5;241m=\u001B[39mcur_epoch, total_examples\u001B[38;5;241m=\u001B[39mtotal_examples, total_words\u001B[38;5;241m=\u001B[39mtotal_words,\n\u001B[0;32m   1080\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\IA\\4t Quadri\\PLH\\env\\Lib\\site-packages\\gensim\\models\\word2vec.py:1434\u001B[0m, in \u001B[0;36mWord2Vec._train_epoch\u001B[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001B[0m\n\u001B[0;32m   1431\u001B[0m     thread\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# make interrupting the process with ctrl+c easier\u001B[39;00m\n\u001B[0;32m   1432\u001B[0m     thread\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m-> 1434\u001B[0m trained_word_count, raw_word_count, job_tally \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_epoch_progress\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1435\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprogress_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcur_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcur_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_examples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport_delay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreport_delay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_corpus_file_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1437\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1439\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001B[1;32m~\\IA\\4t Quadri\\PLH\\env\\Lib\\site-packages\\gensim\\models\\word2vec.py:1289\u001B[0m, in \u001B[0;36mWord2Vec._log_epoch_progress\u001B[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001B[0m\n\u001B[0;32m   1286\u001B[0m unfinished_worker_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkers\n\u001B[0;32m   1288\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m unfinished_worker_count \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1289\u001B[0m     report \u001B[38;5;241m=\u001B[39m \u001B[43mprogress_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# blocks if workers too slow\u001B[39;00m\n\u001B[0;32m   1290\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m report \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# a thread reporting that it finished\u001B[39;00m\n\u001B[0;32m   1291\u001B[0m         unfinished_worker_count \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\queue.py:171\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qsize():\n\u001B[1;32m--> 171\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be a non-negative number\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model100 = word2vec.Word2Vec(txt_crps100 , vector_size=100, window=5, min_count=10, workers=4, epochs=25, sg=1)\n",
    "model500 = word2vec.Word2Vec(txt_crps500 , vector_size=100, window=5, min_count=10, workers=4, epochs=25, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text similarity training and comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtain the Baseline model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare results with different word embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. One Hot encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# limitar mida?, normalitzar?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Models de Word2Vec/GloVe pre-entrenats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1.Word2Vec + Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.2.Word2Vec + Mean ponderada (TF-IDF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.Spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.RoBERTa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.1.CLS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (Amb spaCy, doc._.trf_data.tensors[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.2.MEAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (Amb spaCy, doc._.trf_data.tensors[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.RoBERTa FineTuned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the same model with initiated trainable embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Embeddings (uniforme)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze results"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
